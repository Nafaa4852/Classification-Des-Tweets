{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f6ee8139570>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.autograd as ag\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "th.manual_seed(1) # set the seed \n",
    "\n",
    "#import imdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = \"/home/nafaa/Documents/Projet_TER/Sentiment Analysis Dataset.csv\"\n",
    "file = open(fname, \"r\")\n",
    "labels= [] \n",
    "train = []\n",
    "\n",
    "   \n",
    "reader = csv.reader(file)\n",
    "\n",
    "for row in reader:\n",
    "       \n",
    "        train.append(row[3].lstrip().strip())\n",
    "        labels.append(row[1])\n",
    "#supprimer la colonne sentiment et sentiment text        \n",
    "train.remove('SentimentText')  \n",
    "labels.remove('Sentiment')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1578614\n",
      "1578614\n"
     ]
    }
   ],
   "source": [
    "print(len(labels))\n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 500 0000 données pour le test \n",
    "train_test=train[-500000:]\n",
    "labels_test=labels[-500000:]\n",
    "# 1 million données pour l'apprentissage \n",
    "train=train[:1000000]\n",
    "labels=labels[:1000000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000\n",
      "500000\n",
      "1000000\n",
      "1000000\n"
     ]
    }
   ],
   "source": [
    "print(len(labels_test))\n",
    "print(len(train_test))\n",
    "print(len(labels))\n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mettre les donnes dans un array \n",
    "train=np.asarray(train)\n",
    "labels=np.asarray(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fonction pour séparer la phrase et avoir des mots \n",
    "def phrase_to_mot(x):\n",
    "    word=\"\"\n",
    "    word_list=[]\n",
    "    b=True\n",
    "    for i in range(len(x)): # à l'aid de la méthode isalpha on vérifie si c'est alphabet \n",
    "        if x[i].isalpha() or x[i]==\"@\" or x[i]==\"&\":\n",
    "            if b:\n",
    "                word=word+x[i]\n",
    "                if i+1==len(x):\n",
    "                    word_list.append(word)\n",
    "            else:\n",
    "                b=True\n",
    "                word= word+x[i]\n",
    "\n",
    "        else:\n",
    "            b=False\n",
    "            if word!=\"\":\n",
    "                word_list.append(word)\n",
    "            word=\"\"\n",
    "        if word==\"http\" or word==\"www\":\n",
    "            word_list.append(x)\n",
    "            break\n",
    "   \n",
    "    return word_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dictionnaire contient tout les mots \n",
    "dic={}\n",
    "dic_inverse={}\n",
    "couts=[]\n",
    "k=0\n",
    "for sentense in train:\n",
    "    word_list=phrase_to_mot(sentense)\n",
    "    for word in word_list:\n",
    "        if word not in dic:\n",
    "            dic[word]=k\n",
    "            k+=1\n",
    "            dic_inverse[k]=word\n",
    "            couts.append(1)\n",
    "        else:\n",
    "            index=dic[word]\n",
    "            couts[index]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# un nouveau dictionnaire qui contient les mots qui apparait plus de 20 fois et moins de 10000 fois\n",
    "nouveau_dic={}\n",
    "nouveau_dic_inverse={}\n",
    "k=1\n",
    "for i in range(len(couts)):\n",
    "    if (couts[i]>20):\n",
    "        if (couts[i]<10000):\n",
    "            word=dic_inverse[i]\n",
    "            nouveau_dic[word]=k\n",
    "            nouveau_dic_inverse[k]=word\n",
    "            k+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fonction qui associé un nombre(la clé du mot dans le dictionnaire ) à chaque mot , si il n'existe pas dans le dictionnaire on le met 0\n",
    "def compte(sentense):\n",
    "    word_list=phrase_to_mot(sentense)\n",
    "    l=[]\n",
    "    for i in range(len(word_list)):\n",
    "        if word_list[i] in nouveau_dic:\n",
    "            k=nouveau_dic[word_list[i]]\n",
    "            if k not in l:\n",
    "                l.append(k)\n",
    "        else:\n",
    "            l.append(0)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71, 72, 1, 5, 73, 27, 74, 75, 0]\n",
      "&lt;-------- This is the way i feel right now...\n"
     ]
    }
   ],
   "source": [
    "print(compte(train[15]))\n",
    "print(train[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#construire nouveau train et test , contient une list des tableaux convertie en entier  \n",
    "nouveau_train=[]\n",
    "nouveau_test=[]\n",
    "for tweet in train:\n",
    "    nouveau_train.append(compte(tweet))\n",
    "train1=np.asarray(nouveau_train)\n",
    "\n",
    "for sentense in train_test:\n",
    "    nouveau_test.append(compte(sentense))\n",
    "test1=np.asarray(nouveau_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convertir les labels en entier \n",
    "labels=np.asarray([int(y) for y in labels])\n",
    "labels_test=np.asarray([int (y ) for y in labels_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#une fonction qui calcule le nombre des sentiments positifs dans les labels\n",
    "def sentiment_positif(labl):\n",
    "    k=0\n",
    "\n",
    "    for i in labl:\n",
    "            if i == 1:\n",
    "                k= k+1\n",
    "\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#une fonction qui calcule le nombre des sentiments négatifs dans les labels\n",
    "def sentiment_negatif(labl):\n",
    "    k=0\n",
    "\n",
    "    for i in labl:\n",
    "            if i != 1:\n",
    "                k= k+1\n",
    "\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_proba=[] # train_proba[0] contient la probabilité des sentiments négatifs, train_proba[1] positifs\n",
    "test_proba=[] # test_proba[0] contient la probabilité des sentiments négatifs, test_proba[1] positifs\n",
    "\n",
    "#les sentiments positifs pour les données d'apprentissage\n",
    "train_sentiment_1=sentiment_positif(labels)\n",
    "#les sentiments negatifs pour les données d'apprentissage\n",
    "train_sentiment_0=sentiment_negatif(labels)\n",
    "#probabilité des sentiment négatifs \n",
    "train_proba.append(train_sentiment_0/float(len(labels)))\n",
    "#probabilité des sentiment positifs \n",
    "train_proba.append(train_sentiment_1/float(len(labels)))\n",
    "\n",
    "#les sentiments positifs pour les données de test\n",
    "test_sentiment_1=sentiment_positif(labels_test)\n",
    "#les sentiments negatifs pour les données de test\n",
    "test_sentiment_0=sentiment_negatif(labels_test)\n",
    "#probabilité des sentiment négatifs pour les données de test\n",
    "test_proba.append(test_sentiment_0/float(len(labels_test)))\n",
    "#probabilité des sentiment positifs pour les données de test\n",
    "test_proba.append(test_sentiment_1/float(len(labels_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#une fonction qui calcule combien de fois les mots apparaissent dans la phrase négative ou positive\n",
    "def calcul_apparence_mot(data_set,label):\n",
    "    positif=[0 for i in range(len(nouveau_dic)+1)] # un tableau pour sentiments positif meme taille que le dictionnaire +1\n",
    "    negatif=[0 for i in range(len(nouveau_dic)+1)]\n",
    "    for i in range(len(data_set)):\n",
    "        sentence=data_set[i]\n",
    "        for index in sentence:\n",
    "            if label[i]==1:\n",
    "                positif[index]+=1\n",
    "            else:\n",
    "                negatif[index]+=1\n",
    "    return negatif,positif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg,pos =calcul_apparence_mot(train1,labels) # mettre les résultats dans l1 et l2 \n",
    "train_apparence=[]#train_apparence[0] stock combien de fois le mot est dans la phrase négative train_apparence[1] positif\n",
    "train_apparence.append(neg)\n",
    "train_apparence.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proba_juge(train_appa,nbr_sent_pos,nbr_sent_neg):\n",
    "    p0=[]\n",
    "    p1=[]\n",
    "    for i in range(len(train_appa[1])):\n",
    "        p1.append((train_appa[1][i]+1)/float((nbr_sent_pos+10000)))\n",
    "        p0.append((train_appa[0][i]+1)/float((nbr_sent_neg+10000)))\n",
    "    return p0,p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_p =[]\n",
    "p0,p1=proba_juge(train_apparence,train_sentiment_1,train_sentiment_0)\n",
    "train_p.append(p0)\n",
    "train_p.append(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_class(test):\n",
    "    standard_test=test\n",
    "    standard_test=np.asarray(standard_test)\n",
    "    p1=1\n",
    "    p0=1\n",
    "    label=[]\n",
    "    for tweet in standard_test:\n",
    "        for index in tweet:\n",
    "            p1*=train_p[1][index]\n",
    "            p0*=train_p[0][index]\n",
    "        p1*=train_proba[1]\n",
    "        p0*=train_proba[0]\n",
    "        if p1>p0:\n",
    "            label.append(1)\n",
    "        else:\n",
    "            label.append(0)\n",
    "        p1=1\n",
    "        p0=1\n",
    "    return label\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Test=np.asarray(test1)\n",
    "label=predict_class(Test)\n",
    "\n",
    "label=np.asarray(label)\n",
    "mis=0\n",
    "for i in range(len(label)):\n",
    "    if labels_test[i]!=label[i]:\n",
    "        mis+=1\n",
    "print (\"perte: \",mis/float(len(label)))\n",
    "print (\"réussite: \",(len(label)-mis)/float(len(label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(binary=True, max_features = 10000)\n",
    "ctrain= cv.fit_transform(train)\n",
    "ctest= cv.transform(train_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB(alpha=0.5)\n",
    "print (type(labels_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=0.5, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.fit(ctrain,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bnb.score(ctest,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(binary=False, max_features = 5000)\n",
    "ctrain= cv.fit_transform(train)\n",
    "ctest= cv.transform(train_test)\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "bnb = MultinomialNB(alpha=0.5)\n",
    "bnb.fit(ctrain,labels)\n",
    "bnb.score(ctest,labels_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
